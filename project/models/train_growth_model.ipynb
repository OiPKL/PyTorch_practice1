{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchviz import make_dot\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Selected device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 320,\n",
    "    'EPOCHS': 10,\n",
    "    'LEARNING_RATE': 0.01,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'SEED': 41\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train Length: 425\n",
      "y_train Length: 425\n",
      "\n",
      "X_test Length: 7\n",
      "y_test Length: 7\n"
     ]
    }
   ],
   "source": [
    "training_data_folder = rf\"../dataset/prep_data/lettuce/images/training\"\n",
    "test_data_folder = rf\"../dataset/prep_data/lettuce/images/validation\"\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for filename in os.listdir(training_data_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        name, totalDays, vegetableAge = filename.split(\"_\")\n",
    "        totalDays = int(totalDays)\n",
    "        vegetableAge = int(vegetableAge.split(\".\")[0])\n",
    "\n",
    "        if vegetableAge <= totalDays // 4:\n",
    "            label = 1\n",
    "        elif vegetableAge <= 2 * totalDays // 4:\n",
    "            label = 2\n",
    "        elif vegetableAge <= 3 * totalDays // 4:\n",
    "            label = 3\n",
    "        else:\n",
    "            label = 4\n",
    "\n",
    "        image_path = os.path.join(training_data_folder, filename)\n",
    "        X_train.append(image_path)\n",
    "        y_train.append(label)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for filename in os.listdir(test_data_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        name, totalDays, vegetableAge = filename.split(\"_\")\n",
    "        totalDays = int(totalDays)\n",
    "        vegetableAge = int(vegetableAge.split(\".\")[0])\n",
    "\n",
    "        if vegetableAge <= totalDays // 4:\n",
    "            label = 1\n",
    "        elif vegetableAge <= 2 * totalDays // 4:\n",
    "            label = 2\n",
    "        elif vegetableAge <= 3 * totalDays // 4:\n",
    "            label = 3\n",
    "        else:\n",
    "            label = 4\n",
    "\n",
    "        image_path = os.path.join(test_data_folder, filename)\n",
    "        X_test.append(image_path)\n",
    "        y_test.append(label)\n",
    "\n",
    "print(\"\\nX_train Length:\", len(X_train))\n",
    "print(\"y_train Length:\", len(y_train))\n",
    "print(\"\\nX_test Length:\", len(X_test))\n",
    "print(\"y_test Length:\", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode=True, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.train_mode = train_mode\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        label = self.label_list[index]\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train, y_train, train_mode=True, transforms=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataset = CustomDataset(X_test, y_test, train_mode=False, transforms=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class train_model(nn.Module):\n",
    "    def __init__(self, num_channels=128, final_output_size=(1, 1), num_classes=1):\n",
    "        super(train_model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(8, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(32, num_channels, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(final_output_size),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_channels * final_output_size[0] * final_output_size[1], num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# 모델 생성\n",
    "model = train_model(num_channels=128, final_output_size=(1, 1), num_classes=1)\n",
    "\n",
    "# 모델 출력 확인\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 8, 320, 320]             608\n",
      "              ReLU-2          [-1, 8, 320, 320]               0\n",
      "         MaxPool2d-3          [-1, 8, 160, 160]               0\n",
      "            Conv2d-4         [-1, 16, 160, 160]           3,216\n",
      "              ReLU-5         [-1, 16, 160, 160]               0\n",
      "         MaxPool2d-6           [-1, 16, 80, 80]               0\n",
      "            Conv2d-7           [-1, 32, 80, 80]          12,832\n",
      "              ReLU-8           [-1, 32, 80, 80]               0\n",
      "         MaxPool2d-9           [-1, 32, 40, 40]               0\n",
      "           Conv2d-10          [-1, 128, 40, 40]         102,528\n",
      "             ReLU-11          [-1, 128, 40, 40]               0\n",
      "AdaptiveAvgPool2d-12            [-1, 128, 1, 1]               0\n",
      "          Flatten-13                  [-1, 128]               0\n",
      "           Linear-14                    [-1, 1]             129\n",
      "================================================================\n",
      "Total params: 119,313\n",
      "Trainable params: 119,313\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.17\n",
      "Forward/backward pass size (MB): 27.74\n",
      "Params size (MB): 0.46\n",
      "Estimated Total Size (MB): 29.36\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = train_model().to(device)\n",
    "summary(model, (3, 320, 320), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # original\n",
    "\n",
    "# class train_model(nn.Module):\n",
    "#     def __init__(self, num_classes=1):\n",
    "#         super(train_model, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "#             nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "#             nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#         )\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(256 * 7 * 7, 4096),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, num_classes),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.classifier(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # original\n",
    "\n",
    "# import torch\n",
    "# from torchsummary import summary\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = train_model().to(device)\n",
    "# summary(model, (3, 320, 320), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class train_model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(train_model, self).__init__()\n",
    "#         # Layer 1: Convolutional, BatchNorm, ReLU, MaxPooling\n",
    "#         self.layer1 = nn.Sequential(\n",
    "#             nn.Conv2d(3, 8, kernel_size=5, stride=1, padding=2),\n",
    "#             nn.BatchNorm2d(8),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "#         # Layer 2: Convolutional, BatchNorm, ReLU, MaxPooling\n",
    "#         self.layer2 = nn.Sequential(\n",
    "#             nn.Conv2d(8, 16, kernel_size=5, stride=1, padding=2),\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "#         # Layer 3: Convolutional, BatchNorm, ReLU, MaxPooling\n",
    "#         self.layer3 = nn.Sequential(\n",
    "#             nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "#         # Layer 4: Convolutional, BatchNorm, ReLU, MaxPooling\n",
    "#         self.layer4 = nn.Sequential(\n",
    "#             nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "#         # Layer 5: Convolutional, BatchNorm, ReLU, MaxPooling\n",
    "#         self.layer5 = nn.Sequential(\n",
    "#             nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "#         # Layer 6: Convolutional, BatchNorm, ReLU, MaxPooling\n",
    "#         self.layer6 = nn.Sequential(\n",
    "#             nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "#         # Layer 7: Convolutional, BatchNorm, ReLU, MaxPooling\n",
    "#         self.layer7 = nn.Sequential(\n",
    "#             nn.Conv2d(256, 512, kernel_size=5, stride=1, padding=2),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "#         # Regressor Layer\n",
    "#         self.regressor = nn.Linear(512 * 2 * 2, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.layer3(x)\n",
    "#         x = self.layer4(x)\n",
    "#         x = self.layer5(x)\n",
    "#         x = self.layer6(x)\n",
    "#         x = self.layer7(x)\n",
    "#         x = torch.flatten(x, start_dim=1)\n",
    "#         out = self.regressor(x)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torchsummary import summary\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = train_model().to(device)\n",
    "# summary(model, (3, 320, 320), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'simple_model_graph.png'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = train_model().to(device)\n",
    "\n",
    "input_data = torch.randn((1, 3, 320, 320)).to(device)\n",
    "\n",
    "output = model(input_data)\n",
    "graph = make_dot(output, params=dict(model.named_parameters()))\n",
    "\n",
    "graph.render(\"simple_model_graph\", format=\"png\", cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validation(model, train_loader, criterion, device):\n",
    "#     model.eval()\n",
    "#     vali_loss = []\n",
    "#     vali_label_list = []\n",
    "#     vali_pred_list = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for img, label in tqdm(iter(train_loader)):\n",
    "#             img, label = img.float().to(device), label.float().to(device)\n",
    "\n",
    "#             logit = model(img)\n",
    "#             loss = criterion(logit.squeeze(1), label)\n",
    "            \n",
    "#             vali_loss.append(loss.item())\n",
    "\n",
    "#             vali_label_list.extend(label.cpu().numpy())\n",
    "#             vali_pred_list.extend(logit.squeeze(1).cpu().numpy())\n",
    "\n",
    "#     vali_mae_loss = np.mean(vali_loss)\n",
    "#     return vali_mae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader, device):\n",
    "    threshold=0.5\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            predictions = (outputs > threshold).float()\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, optimizer, train_loader, scheduler, device):\n",
    "#     model.to(device)\n",
    "\n",
    "#     criterion = nn.L1Loss().to(device)\n",
    "#     best_mae = 9999\n",
    "    \n",
    "#     for epoch in range(1, CFG[\"EPOCHS\"] + 1):\n",
    "#         model.train()\n",
    "#         train_loss = []\n",
    "#         for img, label in tqdm(iter(train_loader)):\n",
    "#             img, label = img.float().to(device), label.float().to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "#             logit = model(img)\n",
    "#             loss = criterion(logit.squeeze(1), label)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             train_loss.append(loss.item())\n",
    "\n",
    "#         if scheduler is not None:\n",
    "#             scheduler.step()\n",
    "\n",
    "#         vali_mae = validation(model, train_loader, criterion, device)\n",
    "#         print(f'Epoch [{epoch}] Train MAE : [{np.mean(train_loss):.5f}] Validation MAE : [{vali_mae:.5f}]\\n')\n",
    "\n",
    "#         if best_mae > vali_mae:\n",
    "#             best_mae = vali_mae\n",
    "#             os.makedirs('./saved', exist_ok=True)\n",
    "#             torch.save(model.state_dict(), './saved/best_model.pth')\n",
    "#             print('Model Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.L1Loss().to(device)\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    \n",
    "    for epoch in range(1, CFG[\"EPOCHS\"] + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for img, label in tqdm(iter(train_loader)):\n",
    "            img, label = img.float().to(device), label.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logit = model(img)\n",
    "            loss = criterion(logit.squeeze(1), label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            predictions = (logit > 0.5).float()\n",
    "            y_true.extend(label.cpu().numpy())\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        print(f'Epoch [{epoch}] Train Loss: [{np.mean(train_loss):.5f}] Train Accuracy: [{accuracy:.5f}]\\n')\n",
    "\n",
    "        train_losses.append(np.mean(train_loss))\n",
    "        train_accuracies.append(accuracy)\n",
    "\n",
    "        if best_accuracy < accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            os.makedirs('./saved', exist_ok=True)\n",
    "            torch.save(model.state_dict(), './saved/best_model.pth')\n",
    "            print('Model Saved.')\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(train_accuracies, label='Train Accuracy', color='orange')\n",
    "    plt.title('Train Loss and Accuracy Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss/Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, test_loader, device):\n",
    "#     model.eval()\n",
    "#     vali_label_list = []\n",
    "#     vali_pred_list = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for img, label in tqdm(iter(test_loader)):\n",
    "#             img, label = img.float().to(device), label.float().to(device)\n",
    "#             logit = model(img)\n",
    "#             vali_label_list.extend(label.cpu().numpy())\n",
    "#             vali_pred_list.extend(logit.squeeze(1).detach().cpu().numpy())\n",
    "\n",
    "#     vali_mae = mean_absolute_error(vali_label_list, vali_pred_list)\n",
    "#     print(f\"Test MAE: {vali_mae:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device):\n",
    "    threshold = 0.5\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            predictions = (outputs > threshold).float()\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f13ec776f940a0b77eda7889e9b7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhksw\\Documents\\work\\PyTorch_practice1\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Train Loss: [2.53970] Train Accuracy: [0.00000]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d775c555f27d46859474190e9cf572b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhksw\\Documents\\work\\PyTorch_practice1\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2] Train Loss: [2.39687] Train Accuracy: [0.00000]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0858c97fa94a37b280e974c15b6959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhksw\\Documents\\work\\PyTorch_practice1\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3] Train Loss: [1.58877] Train Accuracy: [0.16471]\n",
      "\n",
      "Model Saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af70385486d470d9e644fd87c2d7fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhksw\\Documents\\work\\PyTorch_practice1\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4] Train Loss: [1.25517] Train Accuracy: [0.24706]\n",
      "\n",
      "Model Saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec7b6ad6efc4e8b9bf4d29232b93164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhksw\\Documents\\work\\PyTorch_practice1\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5] Train Loss: [1.28250] Train Accuracy: [0.24706]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f6740c49d94cb8aa9d04def118da6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhksw\\Documents\\work\\PyTorch_practice1\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6] Train Loss: [1.18358] Train Accuracy: [0.24706]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9405d25d95ee414ea935a11771a6ff85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhksw\\Documents\\work\\PyTorch_practice1\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7] Train Loss: [1.22368] Train Accuracy: [0.24706]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f143e5567a4535b42910c24c17e08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhksw\\Documents\\work\\PyTorch_practice1\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8] Train Loss: [1.07356] Train Accuracy: [0.24706]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07aa43d1bbed4a8d82b2fb634d5a6044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhksw\\Documents\\work\\PyTorch_practice1\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9] Train Loss: [1.18199] Train Accuracy: [0.24706]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71bead4a5dd54440a2e04bcb5d93569e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhksw\\Documents\\work\\PyTorch_practice1\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10] Train Loss: [0.87367] Train Accuracy: [0.24706]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train_model().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=CFG[\"LEARNING_RATE\"])\n",
    "scheduler = None\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)\n",
    "\n",
    "train(model, optimizer, train_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.14286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhksw\\Documents\\work\\PyTorch_practice1\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('./saved/best_model.pth')\n",
    "model = train_model().to(device)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "accuracy = evaluate(model, test_loader, device)\n",
    "print(f'Test Accuracy: {accuracy:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch_practice1",
   "language": "python",
   "name": "pytorch_practice1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
